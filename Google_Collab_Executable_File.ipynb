{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_80%_epoch_10_Abhishank_Gaba_20481729_Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishank-gaba/Kaggle-Challenge-Primary-site-classi-cation-in-histopathology-images/blob/master/Google_Collab_Executable_File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJHIx-Kwrt6o",
        "colab_type": "code",
        "outputId": "79fb541e-4af0-47ea-8b2c-73b773febe65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Convolution2D as Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from IPython.display import display\n",
        "from PIL import Image \n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.regularizers import l2\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrOrAtrOSEkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fly4zbfyr6Pw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6pivVigr7Fi",
        "colab_type": "code",
        "outputId": "89e40541-7146-48fb-8dc3-13c2336702be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6874
        }
      },
      "source": [
        "#read data \n",
        "train_df = np.load(\"train_x.npy\")\n",
        "\n",
        "train_label_df = np.load (\"train_label.npy\")\n",
        "\n",
        "test_df = np.load (\"test_x.npy\")\n",
        "\n",
        "\n",
        "# unique classes\n",
        "classes = np.unique(train_label_df)\n",
        "class_dict = {cls: i for i, cls in enumerate(classes)}\n",
        "\n",
        "# tf readable labels\n",
        "Y = [np.eye(len(classes))[class_dict[label]] for label in train_label_df]\n",
        "\n",
        "X_ds = tf.data.Dataset\\\n",
        "    .from_tensor_slices(train_df)\n",
        "\n",
        "ds_iter = iter(X_ds)\n",
        "\n",
        "Y_ds = tf.data.Dataset\\\n",
        "    .from_tensor_slices(Y)\n",
        "\n",
        "ds_iter = iter(Y_ds)\n",
        "\n",
        "print(next(ds_iter).numpy())\n",
        "\n",
        "ds = tf.data.Dataset.zip((X_ds, Y_ds))\\\n",
        "    .batch(32)\\\n",
        "    .repeat(1000)\n",
        "\n",
        "ds_iter = iter(ds)\n",
        "print(next(ds_iter))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "(<tf.Tensor: id=28, shape=(32, 168, 308, 3), dtype=uint8, numpy=\n",
            "array([[[[156, 191, 223],\n",
            "         [170, 199, 229],\n",
            "         [211, 224, 240],\n",
            "         ...,\n",
            "         [236, 235, 235],\n",
            "         [242, 244, 238],\n",
            "         [250, 252, 249]],\n",
            "\n",
            "        [[156, 193, 225],\n",
            "         [163, 197, 231],\n",
            "         [203, 220, 239],\n",
            "         ...,\n",
            "         [242, 241, 237],\n",
            "         [247, 251, 248],\n",
            "         [249, 252, 253]],\n",
            "\n",
            "        [[151, 189, 218],\n",
            "         [162, 189, 223],\n",
            "         [205, 219, 238],\n",
            "         ...,\n",
            "         [250, 249, 248],\n",
            "         [248, 253, 252],\n",
            "         [248, 252, 252]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[188, 196, 220],\n",
            "         [212, 211, 234],\n",
            "         [218, 220, 234],\n",
            "         ...,\n",
            "         [234, 238, 234],\n",
            "         [244, 247, 246],\n",
            "         [244, 246, 250]],\n",
            "\n",
            "        [[155, 185, 214],\n",
            "         [167, 198, 225],\n",
            "         [170, 203, 228],\n",
            "         ...,\n",
            "         [245, 248, 245],\n",
            "         [246, 250, 249],\n",
            "         [246, 249, 249]],\n",
            "\n",
            "        [[150, 190, 211],\n",
            "         [161, 194, 219],\n",
            "         [165, 196, 219],\n",
            "         ...,\n",
            "         [243, 241, 242],\n",
            "         [244, 244, 244],\n",
            "         [242, 243, 242]]],\n",
            "\n",
            "\n",
            "       [[[250, 250, 249],\n",
            "         [246, 249, 248],\n",
            "         [247, 250, 249],\n",
            "         ...,\n",
            "         [247, 247, 248],\n",
            "         [249, 247, 248],\n",
            "         [249, 248, 249]],\n",
            "\n",
            "        [[249, 249, 250],\n",
            "         [248, 250, 250],\n",
            "         [246, 249, 248],\n",
            "         ...,\n",
            "         [248, 247, 248],\n",
            "         [249, 247, 248],\n",
            "         [249, 248, 248]],\n",
            "\n",
            "        [[250, 249, 247],\n",
            "         [250, 249, 249],\n",
            "         [248, 247, 248],\n",
            "         ...,\n",
            "         [249, 248, 249],\n",
            "         [250, 248, 249],\n",
            "         [248, 250, 249]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[248, 247, 247],\n",
            "         [248, 247, 247],\n",
            "         [248, 248, 246],\n",
            "         ...,\n",
            "         [249, 249, 250],\n",
            "         [249, 249, 250],\n",
            "         [248, 249, 249]],\n",
            "\n",
            "        [[248, 247, 247],\n",
            "         [249, 248, 247],\n",
            "         [249, 248, 248],\n",
            "         ...,\n",
            "         [248, 248, 250],\n",
            "         [247, 248, 249],\n",
            "         [248, 249, 247]],\n",
            "\n",
            "        [[248, 247, 248],\n",
            "         [247, 247, 247],\n",
            "         [246, 246, 248],\n",
            "         ...,\n",
            "         [248, 247, 249],\n",
            "         [247, 247, 248],\n",
            "         [246, 245, 244]]],\n",
            "\n",
            "\n",
            "       [[[224, 192, 232],\n",
            "         [220, 180, 230],\n",
            "         [209, 164, 222],\n",
            "         ...,\n",
            "         [146, 118, 200],\n",
            "         [178, 154, 219],\n",
            "         [191, 175, 226]],\n",
            "\n",
            "        [[243, 212, 249],\n",
            "         [235, 196, 247],\n",
            "         [216, 166, 227],\n",
            "         ...,\n",
            "         [101,  64, 155],\n",
            "         [129,  88, 183],\n",
            "         [137, 104, 193]],\n",
            "\n",
            "        [[242, 199, 243],\n",
            "         [225, 176, 232],\n",
            "         [214, 152, 221],\n",
            "         ...,\n",
            "         [105,  69, 159],\n",
            "         [121,  78, 173],\n",
            "         [122,  76, 175]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 92,  52, 151],\n",
            "         [ 87,  51, 151],\n",
            "         [ 84,  49, 148],\n",
            "         ...,\n",
            "         [134,  75, 170],\n",
            "         [171, 109, 188],\n",
            "         [194, 133, 202]],\n",
            "\n",
            "        [[ 89,  60, 158],\n",
            "         [ 85,  56, 158],\n",
            "         [ 85,  57, 157],\n",
            "         ...,\n",
            "         [169, 105, 178],\n",
            "         [204, 145, 205],\n",
            "         [213, 168, 215]],\n",
            "\n",
            "        [[123, 107, 189],\n",
            "         [110,  92, 183],\n",
            "         [113,  93, 182],\n",
            "         ...,\n",
            "         [222, 171, 213],\n",
            "         [239, 214, 230],\n",
            "         [236, 227, 233]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[175, 185, 240],\n",
            "         [185, 195, 244],\n",
            "         [188, 198, 241],\n",
            "         ...,\n",
            "         [139, 132, 227],\n",
            "         [135, 128, 224],\n",
            "         [131, 121, 219]],\n",
            "\n",
            "        [[167, 177, 222],\n",
            "         [181, 190, 236],\n",
            "         [191, 202, 245],\n",
            "         ...,\n",
            "         [149, 146, 228],\n",
            "         [147, 141, 229],\n",
            "         [142, 133, 224]],\n",
            "\n",
            "        [[179, 186, 219],\n",
            "         [181, 190, 228],\n",
            "         [184, 194, 235],\n",
            "         ...,\n",
            "         [157, 155, 227],\n",
            "         [155, 150, 231],\n",
            "         [149, 143, 228]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[249, 249, 249],\n",
            "         [250, 249, 250],\n",
            "         [250, 249, 250],\n",
            "         ...,\n",
            "         [107,  97, 213],\n",
            "         [103,  93, 206],\n",
            "         [106,  95, 208]],\n",
            "\n",
            "        [[249, 248, 249],\n",
            "         [249, 249, 250],\n",
            "         [248, 249, 250],\n",
            "         ...,\n",
            "         [106,  97, 212],\n",
            "         [107,  99, 206],\n",
            "         [109, 101, 212]],\n",
            "\n",
            "        [[249, 248, 249],\n",
            "         [250, 250, 250],\n",
            "         [249, 249, 249],\n",
            "         ...,\n",
            "         [106,  98, 212],\n",
            "         [111, 105, 209],\n",
            "         [113, 107, 215]]],\n",
            "\n",
            "\n",
            "       [[[244, 185, 235],\n",
            "         [245, 185, 237],\n",
            "         [248, 185, 240],\n",
            "         ...,\n",
            "         [244, 146, 233],\n",
            "         [235, 139, 221],\n",
            "         [238, 144, 224]],\n",
            "\n",
            "        [[245, 174, 239],\n",
            "         [246, 176, 239],\n",
            "         [245, 180, 238],\n",
            "         ...,\n",
            "         [247, 128, 227],\n",
            "         [244, 145, 234],\n",
            "         [249, 156, 238]],\n",
            "\n",
            "        [[240, 185, 236],\n",
            "         [240, 187, 234],\n",
            "         [242, 188, 232],\n",
            "         ...,\n",
            "         [236, 132, 219],\n",
            "         [235, 139, 222],\n",
            "         [242, 152, 230]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[235, 153, 225],\n",
            "         [236, 173, 234],\n",
            "         [233, 187, 235],\n",
            "         ...,\n",
            "         [230, 129, 224],\n",
            "         [227, 152, 226],\n",
            "         [224, 176, 232]],\n",
            "\n",
            "        [[238, 158, 231],\n",
            "         [240, 160, 235],\n",
            "         [238, 158, 233],\n",
            "         ...,\n",
            "         [224, 169, 225],\n",
            "         [223, 155, 216],\n",
            "         [228, 131, 214]],\n",
            "\n",
            "        [[237, 161, 235],\n",
            "         [239, 154, 237],\n",
            "         [242, 149, 235],\n",
            "         ...,\n",
            "         [243, 119, 222],\n",
            "         [243, 112, 228],\n",
            "         [248, 105, 228]]],\n",
            "\n",
            "\n",
            "       [[[245, 244, 245],\n",
            "         [248, 245, 247],\n",
            "         [249, 248, 250],\n",
            "         ...,\n",
            "         [247, 245, 245],\n",
            "         [247, 248, 247],\n",
            "         [243, 244, 244]],\n",
            "\n",
            "        [[245, 243, 245],\n",
            "         [247, 243, 249],\n",
            "         [248, 246, 251],\n",
            "         ...,\n",
            "         [245, 243, 244],\n",
            "         [245, 244, 244],\n",
            "         [243, 241, 241]],\n",
            "\n",
            "        [[243, 241, 241],\n",
            "         [247, 244, 247],\n",
            "         [248, 247, 249],\n",
            "         ...,\n",
            "         [246, 244, 244],\n",
            "         [246, 241, 241],\n",
            "         [244, 239, 237]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 64,  15,   5],\n",
            "         [ 71,  20,  12],\n",
            "         [ 88,  42,  32],\n",
            "         ...,\n",
            "         [239, 227, 226],\n",
            "         [240, 235, 233],\n",
            "         [240, 237, 236]],\n",
            "\n",
            "        [[ 63,  25,  11],\n",
            "         [ 61,  11,   9],\n",
            "         [ 72,  28,  16],\n",
            "         ...,\n",
            "         [236, 219, 213],\n",
            "         [241, 226, 223],\n",
            "         [243, 239, 239]],\n",
            "\n",
            "        [[ 82,  48,  20],\n",
            "         [ 67,  10,   8],\n",
            "         [ 65,  17,   8],\n",
            "         ...,\n",
            "         [219, 200, 185],\n",
            "         [225, 203, 196],\n",
            "         [240, 236, 238]]]], dtype=uint8)>, <tf.Tensor: id=29, shape=(32, 20), dtype=float64, numpy=\n",
            "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1.],\n",
            "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 1., 0., 0.],\n",
            "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 0.],\n",
            "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.]])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1tFP-xUsCwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.0005), input_shape=(168, 308, 3)),\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.0005), input_shape=(168, 308, 3)),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "        \n",
        "    keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "        \n",
        "    keras.layers.Conv2D(128, (3, 3),padding='same', activation='relu'),\n",
        "    keras.layers.Conv2D(128, (3, 3),padding='same', activation='relu'),\n",
        "    keras.layers.MaxPool2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "\n",
        "    \n",
        "    keras.layers.Dense(512, activation='relu'),\n",
        "\n",
        "    keras.layers.Dense(len(classes))\n",
        "]);\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWxDApbYsJZY",
        "colab_type": "code",
        "outputId": "6df69710-5c6f-40ad-9ec8-7b6a6b6f82a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 168, 308, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 168, 308, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 84, 154, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 84, 154, 64)       18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 84, 154, 64)       36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 42, 77, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 42, 77, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 42, 77, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 21, 38, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 102144)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               52298240  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                10260     \n",
            "=================================================================\n",
            "Total params: 52,595,508\n",
            "Trainable params: 52,595,508\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UozVoaMxsU1S",
        "colab_type": "code",
        "outputId": "6713b678-65b2-4d2f-a393-e04b2617fddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer(1e-4)\n",
        "model.compile(optimizer=optimizer, loss=tf.losses.softmax_cross_entropy, metrics=['accuracy'])\n",
        "\n",
        "model.fit( \n",
        "    ds,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        "    verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 6.0146 - acc: 0.5275\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.2355 - acc: 0.9441\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.1307 - acc: 0.9801\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0216 - acc: 1.0000\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0189 - acc: 1.0000\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0179 - acc: 1.0000\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0159 - acc: 1.0000\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0149 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0146 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0143 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff9c7073a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erp0dqV6TbfT",
        "colab_type": "code",
        "outputId": "8c17dd08-5f17-4433-c19c-29e3cfd32410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        }
      },
      "source": [
        "predictions = model.predict(test_df)\n",
        "predictions = np.argmax (predictions, axis=1)\n",
        "print (predictions)\n",
        "\n",
        "result_df = pd.DataFrame({'Id': list(range(len(predictions))), 'Predicted': predictions})\n",
        "result_df.to_csv('results.csv', index=False)\n",
        "\n",
        "files.download('true_results.csv') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10  6  8  7 19 11 17 15  1  7  4  6 18  2 11  3  0 12  8 11 12  4 11 16\n",
            " 15  0 11  5  1  7  7  2 16 13 15 13 15  5  8 19 16  4 11 19 14  2 18  9\n",
            "  9 11  8 13  1 18  2  5 18 13  0  5 15 12  1  2 17 16  5 10 15  1 18 18\n",
            "  2  1  1  4 17  8 16 17  3  8  8 10  7 13 14 14 13 10 16 15 15  5 17 17\n",
            "  6 15 12  3 11  2 14 11  4  9  3 12 17 14  4 15 13 15  8 13  3 15 16 12\n",
            "  2  3 11 14  6  7  1  1 16 16 11 10  4  0 12 10  3 14 14 18  0  2  9  4\n",
            "  5  3 10  5 14  0  4 15  5 11 11 15  3  7 18 19  4  0 17  1  2  6  9  8\n",
            "  4  3 19 13 18 17  3 11  1 17 15  3  9 13 14  8 17 14 16 11  9 10 14  6\n",
            " 17 19 10  9 11  3 18 11]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ca9840b1134c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQqjXm9QUusk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}